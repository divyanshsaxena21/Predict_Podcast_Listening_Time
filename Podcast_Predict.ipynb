{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28",
      "authorship_tag": "ABX9TyPgp0kis06QX1bcKPK8zvs6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/divyanshsaxena21/Predict_Podcast_Listening_Time/blob/main/Podcast_Predict.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MN24IWl3ONaX"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import lightgbm as lgb\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "with zipfile.ZipFile('/content/playground-series-s5e4.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('extracted_files')\n"
      ],
      "metadata": {
        "id": "HzP5IqKNOZ3x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/extracted_files/train.csv')"
      ],
      "metadata": {
        "id": "E5cHHHXBOgtA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qqIhQIELO1m3",
        "outputId": "6b51d337-3533-41a1-fff2-14944e2acd8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['id', 'Podcast_Name', 'Episode_Title', 'Episode_Length_minutes',\n",
              "       'Genre', 'Host_Popularity_percentage', 'Publication_Day',\n",
              "       'Publication_Time', 'Guest_Popularity_percentage', 'Number_of_Ads',\n",
              "       'Episode_Sentiment', 'Listening_Time_minutes'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1uwtqKeuO3Pg",
        "outputId": "95950fc3-48eb-451e-bfda-0a6618a01c67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 750000 entries, 0 to 749999\n",
            "Data columns (total 12 columns):\n",
            " #   Column                       Non-Null Count   Dtype  \n",
            "---  ------                       --------------   -----  \n",
            " 0   id                           750000 non-null  int64  \n",
            " 1   Podcast_Name                 750000 non-null  object \n",
            " 2   Episode_Title                750000 non-null  object \n",
            " 3   Episode_Length_minutes       662907 non-null  float64\n",
            " 4   Genre                        750000 non-null  object \n",
            " 5   Host_Popularity_percentage   750000 non-null  float64\n",
            " 6   Publication_Day              750000 non-null  object \n",
            " 7   Publication_Time             750000 non-null  object \n",
            " 8   Guest_Popularity_percentage  603970 non-null  float64\n",
            " 9   Number_of_Ads                749999 non-null  float64\n",
            " 10  Episode_Sentiment            750000 non-null  object \n",
            " 11  Listening_Time_minutes       750000 non-null  float64\n",
            "dtypes: float64(5), int64(1), object(6)\n",
            "memory usage: 68.7+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define target and features\n",
        "X = df.drop(columns=['Listening_Time_minutes', 'id'])\n",
        "y = df['Listening_Time_minutes']"
      ],
      "metadata": {
        "id": "SUeUA353457b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Handle missing values in numerical columns\n",
        "numerical_features = ['Episode_Length_minutes', 'Host_Popularity_percentage', 'Guest_Popularity_percentage', 'Number_of_Ads']\n",
        "categorical_features = ['Podcast_Name', 'Episode_Title', 'Genre', 'Publication_Day', 'Publication_Time', 'Episode_Sentiment']\n"
      ],
      "metadata": {
        "id": "btFcWcj3PBds"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "3UfIDJZIPcZl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define preprocessing pipeline\n",
        "numerical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='median')),  # Impute missing values with median\n",
        "    ('scaler', StandardScaler())  # Scale numerical data\n",
        "])\n",
        "\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),  # Handle missing categorical data\n",
        "    ('encoder', OneHotEncoder(handle_unknown='ignore'))  # One-hot encode categorical features\n",
        "])\n",
        "\n",
        "# Combine preprocessing steps for numerical and categorical features\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numerical_transformer, numerical_features),\n",
        "        ('cat', categorical_transformer, categorical_features)\n",
        "    ])\n"
      ],
      "metadata": {
        "id": "uppjzkJGPdlY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Train LightGBM model\n",
        "lgbm_model = lgb.LGBMRegressor(n_estimators=100, random_state=42)\n",
        "lgbm_model.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "6yavE0FbGF25",
        "outputId": "d44619ec-271a-433e-ea4e-c29c6bbe3f45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "pandas dtypes must be int, float or bool.\nFields with bad pandas dtypes: Podcast_Name: object, Episode_Title: object, Genre: object, Publication_Day: object, Publication_Time: object, Episode_Sentiment: object",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-62-48b31c694c10>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Step 2: Train LightGBM model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mlgbm_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLGBMRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mlgbm_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_init_score, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[1;32m   1396\u001b[0m     ) -> \"LGBMRegressor\":\n\u001b[1;32m   1397\u001b[0m         \u001b[0;34m\"\"\"Docstring is inherited from the LGBMModel.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1398\u001b[0;31m         super().fit(\n\u001b[0m\u001b[1;32m   1399\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1400\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[1;32m   1047\u001b[0m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord_evaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1049\u001b[0;31m         self._Booster = train(\n\u001b[0m\u001b[1;32m   1050\u001b[0m             \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m             \u001b[0mtrain_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, feval, init_model, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    295\u001b[0m     \u001b[0;31m# construct booster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m         \u001b[0mbooster\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBooster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_valid_contain_train\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m             \u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_train_data_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, params, train_set, model_file, model_str)\u001b[0m\n\u001b[1;32m   3654\u001b[0m                 )\n\u001b[1;32m   3655\u001b[0m             \u001b[0;31m# construct booster object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3656\u001b[0;31m             \u001b[0mtrain_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstruct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3657\u001b[0m             \u001b[0;31m# copy the parameters from train_set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3658\u001b[0m             \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mconstruct\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2588\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2589\u001b[0m                 \u001b[0;31m# create train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2590\u001b[0;31m                 self._lazy_init(\n\u001b[0m\u001b[1;32m   2591\u001b[0m                     \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2592\u001b[0m                     \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m(self, data, label, reference, weight, group, init_score, predictor, feature_name, categorical_feature, params, position)\u001b[0m\n\u001b[1;32m   2121\u001b[0m             \u001b[0mcategorical_feature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreference\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcategorical_feature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2122\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpd_DataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2123\u001b[0;31m             data, feature_name, categorical_feature, self.pandas_categorical = _data_from_pandas(\n\u001b[0m\u001b[1;32m   2124\u001b[0m                 \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2125\u001b[0m                 \u001b[0mfeature_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m_data_from_pandas\u001b[0;34m(data, feature_name, categorical_feature, pandas_categorical)\u001b[0m\n\u001b[1;32m    866\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m     return (\n\u001b[0;32m--> 868\u001b[0;31m         \u001b[0m_pandas_to_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    869\u001b[0m         \u001b[0mfeature_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m         \u001b[0mcategorical_feature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m_pandas_to_numpy\u001b[0;34m(data, target_dtype)\u001b[0m\n\u001b[1;32m    812\u001b[0m     \u001b[0mtarget_dtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"np.typing.DTypeLike\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m ) -> np.ndarray:\n\u001b[0;32m--> 814\u001b[0;31m     \u001b[0m_check_for_bad_pandas_dtypes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    815\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m         \u001b[0;31m# most common case (no nullable dtypes)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m_check_for_bad_pandas_dtypes\u001b[0;34m(pandas_dtypes_series)\u001b[0m\n\u001b[1;32m    803\u001b[0m     ]\n\u001b[1;32m    804\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbad_pandas_dtypes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 805\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    806\u001b[0m             \u001b[0;34mf\"pandas dtypes must be int, float or bool.\\nFields with bad pandas dtypes: {', '.join(bad_pandas_dtypes)}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    807\u001b[0m         )\n",
            "\u001b[0;31mValueError\u001b[0m: pandas dtypes must be int, float or bool.\nFields with bad pandas dtypes: Podcast_Name: object, Episode_Title: object, Genre: object, Publication_Day: object, Publication_Time: object, Episode_Sentiment: object"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate metrics on the training set\n",
        "mse_train = mean_squared_error(y_train, train_predictions)\n",
        "rmse_train = np.sqrt(mse_train)\n",
        "mae_train = mean_absolute_error(y_train, train_predictions)\n",
        "r2_train = r2_score(y_train, train_predictions)\n",
        "\n",
        "# Display the evaluation metrics\n",
        "print(\"Training Set Evaluation Metrics:\")\n",
        "print(f\"R² (R-squared): {r2_train:.4f}\")\n",
        "print(f\"RMSE (Root Mean Squared Error): {rmse_train:.4f}\")\n",
        "print(f\"MAE (Mean Absolute Error): {mae_train:.4f}\")\n",
        "print(f\"MSE (Mean Squared Error): {mse_train:.4f}\")"
      ],
      "metadata": {
        "id": "hFBPryaX1KZg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab22df9b-71ba-46bb-af20-6ce3aeec8dcc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Set Evaluation Metrics:\n",
            "R² (R-squared): 0.7735\n",
            "RMSE (Root Mean Squared Error): 12.9183\n",
            "MAE (Mean Absolute Error): 9.4292\n",
            "MSE (Mean Squared Error): 166.8827\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = pd.read_csv('/content/extracted_files/test.csv')"
      ],
      "metadata": {
        "id": "6zZfFtC0XmMD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pf4o3oEBpJor",
        "outputId": "e5610b51-39c1-4354-f1f4-87eb501c6864"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 250000 entries, 0 to 249999\n",
            "Data columns (total 11 columns):\n",
            " #   Column                       Non-Null Count   Dtype  \n",
            "---  ------                       --------------   -----  \n",
            " 0   id                           250000 non-null  int64  \n",
            " 1   Podcast_Name                 250000 non-null  object \n",
            " 2   Episode_Title                250000 non-null  object \n",
            " 3   Episode_Length_minutes       221264 non-null  float64\n",
            " 4   Genre                        250000 non-null  object \n",
            " 5   Host_Popularity_percentage   250000 non-null  float64\n",
            " 6   Publication_Day              250000 non-null  object \n",
            " 7   Publication_Time             250000 non-null  object \n",
            " 8   Guest_Popularity_percentage  201168 non-null  float64\n",
            " 9   Number_of_Ads                250000 non-null  float64\n",
            " 10  Episode_Sentiment            250000 non-null  object \n",
            "dtypes: float64(4), int64(1), object(6)\n",
            "memory usage: 21.0+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess the test data (same preprocessing steps as for the training data)\n",
        "X_test = test_df.drop(columns=['id'])  # Drop the 'id' column from the test set\n"
      ],
      "metadata": {
        "id": "rfa7J8HkpKoP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict on the test set\n",
        "test_predictions = model_pipeline.predict(X_test)\n"
      ],
      "metadata": {
        "id": "NE7e8s87pgJG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "add80ad2-6604-4838-dd88-d456f10959db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare the submission DataFrame\n",
        "submission = pd.DataFrame({\n",
        "    'id': test_df['id'],  # The 'id' column from the test set\n",
        "    'Listening_Time_minutes': test_predictions  # The predicted values\n",
        "})"
      ],
      "metadata": {
        "id": "J0x5OGMgpsLo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the submission file\n",
        "submission.to_csv('submission_rf_lgbm .csv', index=False)\n",
        "print(\"Submission file has been saved as 'submission.csv'.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7JBure45ptbM",
        "outputId": "d169a32f-b1eb-4859-ef52-694b8e012e42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Submission file has been saved as 'submission.csv'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "a_tQJzdopvCr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}